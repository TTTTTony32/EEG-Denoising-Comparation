"""
ç®€åŒ–ç‰ˆé™å™ªè„šæœ¬
ç”¨äºåœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œé™å™ªå¹¶è¾“å‡ºå®Œæ•´çš„(2700,512)å½¢çŠ¶çš„numpyçŸ©é˜µ
"""
import os
import numpy as np
import torch
from torch.utils.data import DataLoader
from tqdm import tqdm
from model import AbstractDenoiser
from utils.train_valid_utils import get_config, init_model, load_dataset
from accelerate import Accelerator


def simple_denoise():
    """ç®€åŒ–çš„é™å™ªå‡½æ•°"""
    
    # ==================== é…ç½®å‚æ•° ====================
    config_path = "config/retnet/config.yml"
    weight_path = "./results/2024_01_11_15_DiR_4_EOG_pathch16_mini_seq32_hidden_dim512_layer_1_EMG/weight/best.pth"
    output_path = "./denoised_test_output.npy"
    
    # ==================== æ£€æŸ¥æ–‡ä»¶ ====================
    if not os.path.exists(weight_path):
        print(f"é”™è¯¯: æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {weight_path}")
        print("è¯·å…ˆè®­ç»ƒæ¨¡å‹æˆ–æ£€æŸ¥æƒé‡æ–‡ä»¶è·¯å¾„")
        return None
    
    if not os.path.exists("./datasets/test_input.npy"):
        print("é”™è¯¯: æµ‹è¯•æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
        print("è¯·ç¡®ä¿ ./datasets/test_input.npy å’Œ ./datasets/test_output.npy æ–‡ä»¶å­˜åœ¨")
        return None
    
    # ==================== åŠ è½½æ¨¡å‹å’Œæ•°æ® ====================
    print("1. åŠ è½½é…ç½®æ–‡ä»¶...")
    config = get_config(config_path)
    config["model"]["weight_path"] = weight_path
    
    print("2. åˆå§‹åŒ–æ¨¡å‹...")
    model = init_model(config)
    
    print("3. åŠ è½½æµ‹è¯•æ•°æ®...")
    test_x = np.load("./datasets/test_input.npy")
    test_y = np.load("./datasets/test_output.npy")
    print(f"   æµ‹è¯•æ•°æ®å½¢çŠ¶: {test_x.shape}")
    
    # ==================== å‡†å¤‡æ•°æ®åŠ è½½å™¨ ====================
    test_data = {
        'train_x': test_x,
        'train_y': test_y,
        'test_x': test_x,
        'test_y': test_y,
    }
    _, test_dataset = load_dataset(config, custom_data=test_data)
    
    batch_size = config["train"]["batch_size"]
    data_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)
    
    # ==================== è®¾ç½®è®¾å¤‡ ====================
    accelerator = Accelerator()
    model, data_loader = accelerator.prepare(model, data_loader)
    model.eval()
    
    # ==================== æ‰§è¡Œé™å™ª ====================
    print("4. å¼€å§‹é™å™ªå¤„ç†...")
    all_predictions = []
    
    with torch.no_grad():
        for batch in tqdm(data_loader, desc="é™å™ªè¿›åº¦"):
            inputs = batch["y"]
            outputs, _ = model(inputs, inputs)  # ä½¿ç”¨inputsä½œä¸ºlabelsï¼ˆæ¨ç†æ—¶ä¸éœ€è¦çœŸå®æ ‡ç­¾ï¼‰
            
            outputs = accelerator.gather_for_metrics(outputs)
            outputs_np = outputs.cpu().detach().numpy()
            all_predictions.append(outputs_np)
    
    # ==================== åˆå¹¶ç»“æœ ====================
    print("5. åˆå¹¶ç»“æœ...")
    denoised_output = np.concatenate(all_predictions, axis=0)
    
    # ç¡®ä¿è¾“å‡ºå½¢çŠ¶æ­£ç¡®
    if denoised_output.shape[0] > test_x.shape[0]:
        denoised_output = denoised_output[:test_x.shape[0], :]
    
    print(f"   è¾“å‡ºå½¢çŠ¶: {denoised_output.shape}")
    
    # ==================== ä¿å­˜ç»“æœ ====================
    print("6. ä¿å­˜ç»“æœ...")
    np.save(output_path, denoised_output)
    
    # åŒæ—¶ä¿å­˜ä¸ºtxtæ ¼å¼
    txt_path = output_path.replace('.npy', '.txt')
    np.savetxt(txt_path, denoised_output, fmt='%.6f')
    
    print(f"   å·²ä¿å­˜åˆ°: {output_path}")
    print(f"   å·²ä¿å­˜åˆ°: {txt_path}")
    
    return denoised_output


if __name__ == "__main__":
    result = simple_denoise()
    if result is not None:
        print(f"\nâœ… é™å™ªå®Œæˆ!")
        print(f"ğŸ“Š è¾“å‡ºå½¢çŠ¶: {result.shape}")
        print(f"ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   æœ€å°å€¼: {np.min(result):.6f}")
        print(f"   æœ€å¤§å€¼: {np.max(result):.6f}")
        print(f"   å¹³å‡å€¼: {np.mean(result):.6f}")
        print(f"   æ ‡å‡†å·®: {np.std(result):.6f}")
    else:
        print("âŒ é™å™ªå¤±è´¥!") 